# Parliament Explorer - Focused Task List

## üéØ Current Focus: Data Source Understanding & Setup

### Phase 0: API Discovery & Data Mapping (Current Week)

#### ‚úÖ Completed
- [x] Create project structure and directories
- [x] Set up environment files (.env.example, .env.local, .env.production)
- [x] Create exploration directory (gitignored)
- [x] Create OpenParliament API explorer script
- [x] Create data structure analyzer script

#### üîÑ In Progress

**P0.1: Understand OpenParliament API** ‚úÖ COMPLETED
- [x] Run `01_openparliament_api_explorer.py` to discover all endpoints
- [x] Run `02_data_structure_analysis.py` to map schemas
- [x] Document API rate limits and behavior (basic testing done)
- [x] Identify data gaps vs our requirements
- [x] **DECISION: HYBRID - OpenParliament as primary + LEGISinfo enrichment**

**P0.2: Compare with Official Sources** ‚úÖ COMPLETED
- [x] Explore LEGISinfo structure (https://www.parl.ca/legisinfo)
- [x] Explore Hansard structure (https://www.ourcommons.ca/DocumentViewer)
- [x] Explore Committee pages
- [x] Document what each source provides uniquely
- [x] Create source matrix: Entity ‚Üí Best Source
- [x] **DECISION: Hybrid confirmed - LEGISinfo for tags/committees, Parliament.ca for meetings**

**P0.3: Define Adapter Strategy** ‚úÖ COMPLETED
- [x] Choose primary data source per entity type
- [x] Design adapter interface (unified response format)
- [x] Plan for data enrichment (combining sources)
- [x] Document update frequencies per source
- [x] **ARCHITECTURE: BaseAdapter protocol with AdapterResponse[T], rate limiting, retry logic**

#### üìã Next Steps

**P0.4: Initial Project Setup**
- [ ] Create `requirements.txt` with core dependencies
- [ ] Create `pyproject.toml` for Python project
- [ ] Set up `package.json` for frontend
- [ ] Create `docker-compose.yml` for local services
- [ ] Initialize Git repository with .gitignore

**P0.5: Local Development Environment**
- [ ] Start Postgres locally (Docker)
- [ ] Start Redis locally (Docker)
- [ ] Start MinIO locally (Docker)
- [ ] Test database connection
- [ ] Test Redis connection
- [ ] Test MinIO bucket creation

---

## üìä Decision Log

### Decisions to Make

1. **Primary Data Source**
   - Option A: OpenParliament API (if comprehensive)
   - Option B: LEGISinfo scraping (if OpenParliament incomplete)
   - Option C: Hybrid (OpenParliament + selective scraping)
   - **Decision**: _Pending exploration results_

2. **Jurisdiction Naming**
   - Proposal: `ca-federal`, `ca-federal-senate`, `ca-{province-code}`
   - **Decision**: _Approved pending validation_

3. **Natural Key Strategy**
   - Bills: `(jurisdiction, parliament, session, number)`
   - MPs: `(jurisdiction, member_id)` from source
   - **Decision**: _Pending schema design_

4. **Embedding Model**
   - Option A: OpenAI `text-embedding-3-small` (cost-effective)
   - Option B: Local model (Sentence Transformers)
   - Option C: Cohere embeddings
   - **Decision**: _Pending_

---

## üöÄ Quick Commands

### Run Exploration
```powershell
# Install dependencies
pip install httpx requests

# Explore API
python exploration/01_openparliament_api_explorer.py

# Analyze structure
python exploration/02_data_structure_analysis.py

# View results
cat exploration/outputs/ANALYSIS_REPORT.md
```

### Start Local Services (Future)
```powershell
# Start all services
docker-compose up -d

# Check status
docker-compose ps

# View logs
docker-compose logs -f
```

---

## üìù Notes

- **2025-10-17**: Project initialized. Focus: Understand OpenParliament API before building adapters.
- OpenParliament API docs: https://api.openparliament.ca/
- No auth required for read-only access
- Need to verify data freshness and completeness

---

## üîó Resources

- [OpenParliament API](https://api.openparliament.ca/)
- [LEGISinfo](https://www.parl.ca/legisinfo)
- [House of Commons](https://www.ourcommons.ca/)
- [Senate of Canada](https://sencanada.ca/)

---

## ‚è≠Ô∏è After Discovery Phase

Once we understand the data sources, we'll move to:
1. **Phase A**: Railway infrastructure setup
2. **Phase B**: Database schema design based on actual data
3. **Phase C**: Adapter implementation for chosen sources
4. **Phase D**: ETL pipeline with Dagster

**Status**: üü° Discovery phase - understanding data landscape before architecture
